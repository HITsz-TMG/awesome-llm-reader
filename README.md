#  A Repository of Retrieval-augmented LLMs


* [2022/12] **Parallel Context Windows for Large Language Models.** *Nir Ratner et al. ACL.* [[paper](https://arxiv.org/pdf/2212.10947.pdf)]

* [2023/04] **Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines.** *Ruochen Zhao et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2304.11076.pdf)]

* [2023/05] **Active Retrieval Augmented Generation.** *Zhengbao Jiang et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2305.06983.pdf)]

* [2023/05] **Augmented Large Language Models with Parametric Knowledge Guiding.** *Ziyang Luo et al. arXiv.* [[paper](https://arxiv.org/pdf/2305.04757.pdf)]

* [2023/05] **Plug-and-Play Knowledge Injection for Pre-trained Language Models.** *Zhengyan Zhang et al. ACL.* [[paper](https://arxiv.org/pdf/2305.17691.pdf)]

* [2023/05] **Adapting Language Models to Compress Contexts.** *Alexis Chevalier et al. arXiv.* [[paper](https://arxiv.org/pdf/2305.14788.pdf)]

* [2023/05] **RET-LLM: Towards a General Read-Write Memory for Large Language Models.** *Ali Modarressi et al. arXiv.* [[paper](https://arxiv.org/pdf/2305.14322.pdf)]

* [2023/05] **Query Rewriting for Retrieval-Augmented Large Language Models.** *Xinbei Ma et al. EMNLP.* [[paper](https://browse.arxiv.org/pdf/2305.14283.pdf)]

* [2023/05] **Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy.** *Zhihong Shao et al. EMNLP.* [[paper](https://browse.arxiv.org/pdf/2305.15294.pdf)]

* [2023/05] **WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences.** *Xiao Liu et al. KDD.* [[paper](https://arxiv.org/pdf/2306.07906.pdf)]

* [2023/06] **ToolQA: A Dataset for LLM Question Answering with External Tools.** *Yuchen Zhuang et al. arXiv.* [[paper](https://arxiv.org/pdf/2306.13304.pdf)]

* [2023/07] **Thrust: Adaptively Propels Large Language Models with External Knowledge.** *Xinran Zhao et al. arXiv.* [[paper](https://arxiv.org/pdf/2307.10442.pdf)]

* [2023/07] **Chain of Thought Prompting Elicits Knowledge Augmentation.** *Dingjun Wu et al. arXiv.* [[paper](https://arxiv.org/pdf/2307.01640.pdf)]

* [2023/09] **Benchmarking Large Language Models in Retrieval-Augmented Generation.** *Jiawei Chen et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2309.01431v1.pdf)]

* [2023/09] **PDFTriage: Question Answering over Long, Structured Documents.** *Jon Saad-Falcon et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2309.08872v1.pdf)]

* [2023/09] **Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues.** *Norbert Braunschweiler et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2309.11838v1.pdf)]

* [2023/10] **RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation.** *Fangyuan Xu et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.04408v1.pdf)]

* [2023/10] **Retrieval-Generation Synergy Augmented Large Language Models.** *Zhangyin Feng et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.05149v1.pdf)]

* [2023/10] **FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation.** *Tu Vu et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.03214v1.pdf)]

* [2023/10] **Hexa: Self-Improving for Knowledge-Grounded Dialogue System.** *Daejin Jo et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.06404v1.pdf)]

* [2023/10] **Compressing Context to Enhance Inference Efficiency of Large Language Models.** *Yucheng Li et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.06201v1.pdf)]
