#  A Repository of Retrieval-augmented LLMs




* [2023/05] **Active Retrieval Augmented Generation.** *Zhengbao Jiang et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2305.06983.pdf)]

* [2023/05] **Augmented Large Language Models with Parametric Knowledge Guiding.** *Ziyang Luo et al. arXiv.* [[paper](https://arxiv.org/pdf/2305.04757.pdf)]

* [2023/05] **RET-LLM: Towards a General Read-Write Memory for Large Language Models.** *Ali Modarressi et al. arXiv.* [[paper](https://arxiv.org/pdf/2305.14322.pdf)]

* [2023/05] **Query Rewriting for Retrieval-Augmented Large Language Models.** *Xinbei Ma et al. EMNLP.* [[paper](https://browse.arxiv.org/pdf/2305.14283.pdf)]

* [2023/05] **Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy.** *Zhihong Shao et al. EMNLP.* [[paper](https://browse.arxiv.org/pdf/2305.15294.pdf)]

* [2023/05] **WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences.** *Xiao Liu et al. KDD.* [[paper](https://arxiv.org/pdf/2306.07906.pdf)]

* [2023/07] **Chain of Thought Prompting Elicits Knowledge Augmentation.** *Dingjun Wu et al. arXiv.* [[paper](https://arxiv.org/pdf/2307.01640.pdf)]

* [2023/10] **Retrieval-Generation Synergy Augmented Large Language Models.** *Zhangyin Feng et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.05149v1.pdf)]

* [2023/10] **FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation.** *Tu Vu et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.03214v1.pdf)]

* [2023/10] **Hexa: Self-Improving for Knowledge-Grounded Dialogue System.** *Daejin Jo et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.06404v1.pdf)]

* [2023/10] **Retrieve Anything To Augment Large Language Models.** *Peitian Zhang et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.07554.pdf)]

* [2023/10] **Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection.** *Akari Asai et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.11511.pdf)]

* [2024/01] **DocLLM: A layout-aware generative language model for multimodal document understanding.** *Dongsheng Wang et al. arXiv.* [[paper](https://arxiv.org/pdf/2401.00908v1.pdf)]


## :memo: Knowledge Preprocessing

* [2023/09] **PDFTriage: Question Answering over Long, Structured Documents.** *Jon Saad-Falcon et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2309.08872v1.pdf)]

* [2023/10] **Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading.** *Howard Chen et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.05029.pdf)]

* [2023/11] **LLatrieval: LLM-Verified Retrieval for Verifiable Generation.** *Xiaonan Li et al. arXiv.* [[paper](https://arxiv.org/pdf/2311.07838v1.pdf)]

* [2023/11] **Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models.** *Wenhao Yu et al. arXiv.* [[paper](https://arxiv.org/pdf/2311.09210v1.pdf)]

* [2023/11] **Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering.** *Inderjeet Nair et al. arXiv.* [[paper](https://arxiv.org/pdf/2311.13565v1.pdf)]



## :chart_with_upwards_trend: Evaluation

* [2023/04] **Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines.** *Ruochen Zhao et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2304.11076.pdf)]

* [2023/06] **ToolQA: A Dataset for LLM Question Answering with External Tools.** *Yuchen Zhuang et al. arXiv.* [[paper](https://arxiv.org/pdf/2306.13304.pdf)]

* [2023/09] **Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues.** *Norbert Braunschweiler et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2309.11838v1.pdf)]

* [2023/09] **Benchmarking Large Language Models in Retrieval-Augmented Generation.** *Jiawei Chen et al. arXiv.* [[paper](https://browse.arxiv.org/pdf/2309.01431v1.pdf)]

* [2023/10] **Understanding Retrieval Augmentation for Long-Form Question Answering.** *Hung-Ting Chen et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.12150.pdf)]

* [2024/01] **Corrective Retrieval Augmented Generation.** *Shi-Qi Yan et al. arXiv.* [[paper](https://arxiv.org/pdf/2401.15884v1.pdf)]

* [2024/01] **CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models.** *Yuanjie Lyu et al. arXiv.* [[paper](https://arxiv.org/pdf/2401.17043v1.pdf)]



## :rocket: Efficiency

* [2022/12] **Parallel Context Windows for Large Language Models.** *Nir Ratner et al. ACL.* [[paper](https://arxiv.org/pdf/2212.10947.pdf)]

* [2023/05] **Plug-and-Play Knowledge Injection for Pre-trained Language Models.** *Zhengyan Zhang et al. ACL.* [[paper](https://arxiv.org/pdf/2305.17691.pdf)]

* [2023/05] **Adapting Language Models to Compress Contexts.** *Alexis Chevalier et al. arXiv.* [[paper](https://arxiv.org/pdf/2305.14788.pdf)]

* [2023/07] **Thrust: Adaptively Propels Large Language Models with External Knowledge.** *Xinran Zhao et al. arXiv.* [[paper](https://arxiv.org/pdf/2307.10442.pdf)]

* [2023/10] **RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation.** *Fangyuan Xu et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.04408v1.pdf)]

* [2023/10] **Compressing Context to Enhance Inference Efficiency of Large Language Models.** *Yucheng Li et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.06201v1.pdf)]

* [2023/10] **CacheGen: Fast Context Loading for Language Model Applications.** *Yuhan Liu et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.07240.pdf)]

* [2023/10] **TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction.** *Junyi Liu et al. arXiv.* [[paper](https://arxiv.org/pdf/2310.15556v1.pdf)]

* [2023/11] **Learning to Filter Context for Retrieval-Augmented Generation.** *Zhiruo Wang et al. arXiv.* [[paper](https://arxiv.org/pdf/2311.08377v1.pdf)]

* [2024/02] **Generative Representational Instruction Tuning.** *Niklas Muennighoff et al. arXiv.* [[paper](https://arxiv.org/pdf/2402.09906.pdf)]

* [2024/02] **A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts.** *Kuang-Huei Lee et al. arXiv.* [[paper](https://arxiv.org/pdf/2402.09727.pdf)]